{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a good correction term for the shifted cameras\n",
    "\n",
    "In this notebook, we do a small experiment to find a good correction term for the shifted cameras. The idea is the following:\n",
    "The model cannot distinguish between the picture from the center camera of the car if it is slightly off the center of the road and the picture from the shifted camera if the car is on the center of the road. The appropriate correction term should produce in both cases the same steering angle. Hence, an appropriately chosen correction term should prodcue training data which is more consistent.\n",
    "\n",
    "To estimate how consistent the training data is, we fit a small neural network to it and measure the loss function. A smaller loss function indicates that the training data is more consistent and easier to learn. This allows us to test different correction terms and pick this term which prodcues the most consistent training data.\n",
    "\n",
    "## Training set\n",
    "To collect the training set, we drive two laps (clockwise and counter clockwise) of the first track staying on the center of the road.\n",
    "\n",
    "## Experiment\n",
    "The neural network is rather similiar containing one averaging, four convolutional, two max pooling and two fully connected layers. We train it for 3 epochs and report at the end the loss on the complete training data. We repeat the experiment 5 times for each correction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5590\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "samples = []\n",
    "with open('C://DrivingData/Track_1_2_Loops/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_6(samples, batch_size = 10,correction_term = 0.00):\n",
    "    #The effective batch size is 6*batch_size\n",
    "    num_samples = len(samples)\n",
    "    shuffle(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                center_image = cv2.imread(batch_sample[0])\n",
    "                center_angle = float(batch_sample[3])\n",
    "               \n",
    "                img_left = cv2.imread(batch_sample[1])\n",
    "                left_angle = center_angle+correction_term\n",
    "                \n",
    "                img_right = cv2.imread(batch_sample[2])\n",
    "                right_angle = center_angle-correction_term   \n",
    "        \n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "                images.append(img_left)\n",
    "                angles.append(left_angle)\n",
    "\n",
    "                images.append(img_right)\n",
    "                angles.append(right_angle)\n",
    "                                \n",
    "                #Add all Flipped Versions\n",
    "                images.append(np.fliplr(center_image))\n",
    "                angles.append(-center_angle)\n",
    "                \n",
    "                images.append(np.fliplr(img_left))\n",
    "                angles.append(-left_angle)\n",
    "\n",
    "                images.append(np.fliplr(img_right))\n",
    "                angles.append(-right_angle)\n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers import Cropping2D, Conv2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correction_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0051    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 32s - loss: 0.0035    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 32s - loss: 0.0028    \n",
      "0.00248388224677\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0047    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0032    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0022    \n",
      "0.00357699715269\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0055    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0033    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0032    \n",
      "0.00367062414361\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0048    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0026    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0017    \n",
      "0.00240314460846\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0049    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0033    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0024    \n",
      "0.0034391685645\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0052    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0036    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0028    \n",
      "0.00269065723518\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0043    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0028    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 32s - loss: 0.0031    \n",
      "0.00200406818861\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0046    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0040    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0034    \n",
      "0.00387855273389\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0058    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0034    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0029    \n",
      "0.00306445864589\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0073    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0065    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0038    \n",
      "0.00204784884638\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0044    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0028    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0019    \n",
      "0.00200010985241\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0037    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0026    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0020    \n",
      "0.00202650533906\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0055    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 32s - loss: 0.0040    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0030    \n",
      "0.00349934907409\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0050    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0037    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0020    \n",
      "0.00226483576204\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0046    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0022    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 32s - loss: 0.0017    \n",
      "0.0018200599564\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0052    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0031    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0023    \n",
      "0.00193484927731\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 35s - loss: 0.0058    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0039    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0028    \n",
      "0.00197602374579\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0045    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0024    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0028    \n",
      "0.00272162425605\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0046    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0025    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0018    \n",
      "0.00206906548774\n",
      "Epoch 1/3\n",
      "280/279 [==============================] - 34s - loss: 0.0060    \n",
      "Epoch 2/3\n",
      "280/279 [==============================] - 33s - loss: 0.0053    \n",
      "Epoch 3/3\n",
      "280/279 [==============================] - 33s - loss: 0.0036    \n",
      "0.00479091767811\n"
     ]
    }
   ],
   "source": [
    "training_batch_size = 20\n",
    "correction_values = [0,0.01,0.02,0.03]\n",
    "\n",
    "for correction_value in correction_values:\n",
    "    correction_results[correction_value] =[]\n",
    "\n",
    "for i in range(5):\n",
    "    for correction_value in correction_values:\n",
    "        model = Sequential()\n",
    "        model.add(Cropping2D(cropping=((50,20),(0,0)), input_shape=(160,320,3)))\n",
    "        model.add(Lambda(lambda x: (x/255.0)-0.5))\n",
    "        model.add(AveragePooling2D(pool_size = 2))\n",
    "        model.add(Conv2D(6,(3,3),activation = 'relu'))\n",
    "        model.add(Conv2D(6,(3,3),activation = 'relu'))\n",
    "        model.add(MaxPooling2D(pool_size = 2))\n",
    "        model.add(Conv2D(12,(3,3),activation = 'relu'))\n",
    "        model.add(Conv2D(12,(3,3),activation = 'relu'))\n",
    "        model.add(MaxPooling2D(pool_size = 2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(25,activation = 'relu'))\n",
    "        model.add(Dense(10,activation = 'relu'))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        train_generator = generate_6(samples,training_batch_size,correction_value)\n",
    "\n",
    "        model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "        s_p_e_t = len(samples)/training_batch_size\n",
    "        \n",
    "        model.fit_generator(train_generator, steps_per_epoch = s_p_e_t, epochs = 3,verbose = 1)\n",
    "\n",
    "        correction_fit = model.evaluate_generator(train_generator, steps = s_p_e_t)\n",
    "        print(correction_fit)\n",
    "\n",
    "        correction_results[correction_value].append(correction_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0024838822467705777, 0.0034391685644981464, 0.0030644586458850121, 0.0034993490740891768, 0.0019760237457851293], 0.02: [0.0036706241436135225, 0.0020040681886131424, 0.0020001098524120159, 0.0018200599563983643, 0.0020690654877437678], 0.03: [0.0024031446084600071, 0.0038785527338889639, 0.0020265053390566517, 0.0019348492773107297, 0.0047909176781084657], 0.01: [0.0035769971526891813, 0.0026906572351767808, 0.0020478488463766403, 0.0022648357620440075, 0.0027216242560500377]}\n"
     ]
    }
   ],
   "source": [
    "print(correction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcb525ca128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_points = []\n",
    "y_points = []\n",
    "\n",
    "x_points_mean = []\n",
    "y_means =[]\n",
    "\n",
    "for key, value in sorted(correction_results.items()):\n",
    "    mean = 0\n",
    "    for v in value:\n",
    "        x_points.append(key)\n",
    "        y_points.append(v)\n",
    "        mean += v\n",
    "    mean /= len(value)\n",
    "    x_points_mean.append(key)\n",
    "    y_means.append(mean)\n",
    "        \n",
    "plt.plot(x_points,y_points,'ro')\n",
    "plt.plot(x_points_mean,y_means)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "As expected the different correction terms produce training data of different consistency. According to our experiments, a correction term of 0.02 seems to be appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
